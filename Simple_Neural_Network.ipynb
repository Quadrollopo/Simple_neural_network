{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di Simple_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIspOKyJ4kxH7wGYDvw70u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Yhn_LBY_eUh",
        "outputId": "c3595c09-a99b-4d2c-d93b-41c9e559ac98"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib.pyplot import plot, show\n",
        "\n",
        "\n",
        "def generate_input(input_neurons, output_neurons):\n",
        "    num = np.random.randint(256)\n",
        "    bits = np.binary_repr(num, input_neurons)\n",
        "    sol = np.zeros((output_neurons, 1))\n",
        "    sol[num % 4] = 1\n",
        "    arr = np.empty((input_neurons, 1))\n",
        "    for i in range(input_neurons):\n",
        "        b = int(bits[i])\n",
        "        arr[i] = b\n",
        "    return arr, sol\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def der_sigmoid(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "def forward(weights, bias, lay):\n",
        "    num = len(weights)\n",
        "    layers_raw = np.empty(num, dtype = np.ndarray)\n",
        "    layers = np.empty(num + 1, dtype = np.ndarray)\n",
        "    for i in range(num):\n",
        "        layers[i] = lay\n",
        "        output = weights[i] @ lay + bias[i]\n",
        "        layers_raw[i] = output\n",
        "        lay = np.maximum(output, 0)\n",
        "    layers[-1] = sigmoid(output)\n",
        "    return layers, layers_raw\n",
        "\n",
        "\n",
        "def backpropagation(bias_gradient, weight_gradient, layers, layers_raw, weights, cost):\n",
        "    # first backpropagation is special since use a different activation function\n",
        "    tmp_bias = cost * der_sigmoid(layers_raw[-1])\n",
        "    bias_gradient[-1] -= tmp_bias\n",
        "    weight_gradient[-1] -= tmp_bias @ layers[-2].T\n",
        "    cost = weights[-1].T @ tmp_bias\n",
        "    for i in range(2, len(weights)):\n",
        "        tmp_bias = cost * np.heaviside(layers_raw[-i], 0)\n",
        "        bias_gradient[-i] -= tmp_bias\n",
        "        weight_gradient[-i] -= tmp_bias @ layers[-i - 1].T\n",
        "        cost = weights[-i].T @ tmp_bias\n",
        "\n",
        "    tmp_bias = cost * np.heaviside(layers_raw[0], 0)\n",
        "    bias_gradient[0] -= tmp_bias\n",
        "    weight_gradient[0] -= tmp_bias @ layers[0].T\n",
        "\n",
        "\n",
        "def validation(weights, bias, num_input, num_output):\n",
        "    found = 0\n",
        "    for n in range(val_num):\n",
        "        in_layer, sol = generate_input(num_input, num_output)\n",
        "        output, _ = forward(weights, bias, in_layer)\n",
        "        if ((output[-1] > 0.6) == (sol > 0.6)).all():\n",
        "            found += 1\n",
        "    print(found / val_num)\n",
        "\n",
        "\n",
        "def neural_network(num_neurons: list):\n",
        "    global learning_rate\n",
        "    num_layers = len(num_neurons)\n",
        "    if num_layers < 2:\n",
        "        print(\"Non hai specificato abbastanza layer di neuroni\")\n",
        "        exit(-1)\n",
        "    bias = np.empty(num_layers - 1, dtype = np.ndarray)\n",
        "    weights = np.empty(num_layers - 1, dtype = np.ndarray)\n",
        "    bias_gradient = np.empty(num_layers - 1, dtype = np.ndarray)\n",
        "    weights_gradient = np.empty(num_layers - 1, dtype = np.ndarray)\n",
        "    for i in range(num_layers - 1):\n",
        "        bias[i] = (np.zeros((num_neurons[i+1], 1)))\n",
        "        weights[i] = (np.random.rand(num_neurons[i+1], num_neurons[i]))\n",
        "        bias_gradient[i] = (np.zeros((num_neurons[i+1], 1)))\n",
        "        weights_gradient[i] = (np.random.rand(num_neurons[i+1], num_neurons[i]))\n",
        "\n",
        "    for k in range(num_epoch):\n",
        "        loss = 0\n",
        "        bias_gradient = bias_gradient * 0\n",
        "        weights_gradient = weights_gradient * 0\n",
        "        for i in range(batch_size):\n",
        "            inp, sol = generate_input(num_neurons[0], num_neurons[-1])\n",
        "            layers, layers_raw = forward(weights, bias, inp)\n",
        "            output = layers[-1]\n",
        "            loss += np.square(output - sol).sum()\n",
        "\n",
        "            # detras propagar\n",
        "            backpropagation(bias_gradient, weights_gradient, layers, layers_raw, weights, (output - sol) * 2)\n",
        "\n",
        "        bias += learning_rate * bias_gradient / batch_size\n",
        "        weights += learning_rate * weights_gradient / batch_size\n",
        "\n",
        "        if k % 20 == 0 and k != 0:\n",
        "            loss = loss / batch_size\n",
        "            history.append(loss)\n",
        "            print(f'Loss: {loss} LS:{learning_rate}')\n",
        "        if k % descend_step == 0 and k != 0:\n",
        "            learning_rate /= 10\n",
        "    return weights, bias\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    num_epoch = 1000\n",
        "    batch_size = 64\n",
        "    learning_rate = 0.5\n",
        "    descend_step = numEpoch // 2\n",
        "    val_num = 1000\n",
        "    history = []\n",
        "    network = [8, 4, 4]\n",
        "    weights, bias = neural_network(network)\n",
        "    validation(weights, bias, network[0], network[-1])\n",
        "    plot(range(20, numEpoch, 20), history)\n",
        "    show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.7237329700831349 LS:0.5\n",
            "Loss: 0.6927436348237273 LS:0.5\n",
            "Loss: 0.5302856736305587 LS:0.5\n",
            "Loss: 0.40037188208022295 LS:0.5\n",
            "Loss: 0.2070426751279524 LS:0.5\n",
            "Loss: 0.08366620137744381 LS:0.5\n",
            "Loss: 0.05929111826165648 LS:0.5\n",
            "Loss: 0.033717285564688323 LS:0.5\n",
            "Loss: 0.022942606683027427 LS:0.5\n",
            "Loss: 0.01981590325446108 LS:0.5\n",
            "Loss: 0.014455723599885307 LS:0.5\n",
            "Loss: 0.01640354433259456 LS:0.5\n",
            "Loss: 0.012303455054222695 LS:0.5\n",
            "Loss: 0.00966483588740292 LS:0.5\n",
            "Loss: 0.008013038432182496 LS:0.5\n",
            "Loss: 0.008001950134065076 LS:0.5\n",
            "Loss: 0.007819240988891264 LS:0.5\n",
            "Loss: 0.006441358920602711 LS:0.5\n",
            "Loss: 0.0051462682262477695 LS:0.5\n",
            "Loss: 0.0050760554908995245 LS:0.5\n",
            "Loss: 0.0042886813462140756 LS:0.5\n",
            "Loss: 0.00488478939707116 LS:0.5\n",
            "Loss: 0.0038407842869677133 LS:0.5\n",
            "Loss: 0.004104335344596515 LS:0.5\n",
            "Loss: 0.0031689745913388036 LS:0.5\n",
            "Loss: 0.003118309768851364 LS:0.05\n",
            "Loss: 0.0036586530591586875 LS:0.05\n",
            "Loss: 0.0029104910809572664 LS:0.05\n",
            "Loss: 0.003367759865273141 LS:0.05\n",
            "Loss: 0.0032498488997319765 LS:0.05\n",
            "Loss: 0.0034700366841504764 LS:0.05\n",
            "Loss: 0.003036683329448036 LS:0.05\n",
            "Loss: 0.0035334559595677313 LS:0.05\n",
            "Loss: 0.0033975367685834487 LS:0.05\n",
            "Loss: 0.0035040509471335386 LS:0.05\n",
            "Loss: 0.00412155610826497 LS:0.05\n",
            "Loss: 0.0033826632346958116 LS:0.05\n",
            "Loss: 0.003494116809509563 LS:0.05\n",
            "Loss: 0.0029597515390617176 LS:0.05\n",
            "Loss: 0.0032019457692473974 LS:0.05\n",
            "Loss: 0.003869155095554985 LS:0.05\n",
            "Loss: 0.0030753278884896587 LS:0.05\n",
            "Loss: 0.00388476367033675 LS:0.05\n",
            "Loss: 0.003649484504316674 LS:0.05\n",
            "Loss: 0.0032794129530224997 LS:0.05\n",
            "Loss: 0.0036794868204657765 LS:0.05\n",
            "Loss: 0.003364523159885529 LS:0.05\n",
            "Loss: 0.003902324224955906 LS:0.05\n",
            "Loss: 0.0027404663231348414 LS:0.05\n",
            "1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K52ERSseQp1c",
        "outputId": "8d96d74d-f94b-45fc-9eba-1a8c3a879828"
      },
      "source": [
        "test_manually(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    }
  ]
}